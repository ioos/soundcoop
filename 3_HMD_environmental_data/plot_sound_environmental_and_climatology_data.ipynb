{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate and plot sound, environmental, and climatology data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't need to run the installation when on mybinder, this has been taken care of for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install rioxarray\n",
    "!pip install hvplot\n",
    "!pip install geopandas\n",
    "!pip install cartopy\n",
    "!pip install geoviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta\n",
    "import hvplot.pandas\n",
    "from shapely import wkt, geometry\n",
    "import geopandas as gpd\n",
    "import minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Supress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Clear out default notebook settings\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches':None}\n",
    "\n",
    "# Set figure size and layout\n",
    "plt.rcParams[\"figure.figsize\"] = [12.00, 5.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set sound and environmental dataset variables\n",
    "\n",
    "Find variables by exploring https://soundcoop.portal.axds.co."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erddap_dataset = 'gov-ndbc-44007'\n",
    "sound_dataset = 'Monh'\n",
    "max_days = 25\n",
    "start_date_time = '2021-10-23T20:11:53.211'\n",
    "end_date_time = '2021-11-18T07:28:18.297'\n",
    "min_frequency = 21\n",
    "max_frequency = 24000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update end_date_time if defined temporal range exceeds max_days\n",
    "time_delta = datetime.fromisoformat(end_date_time) - datetime.fromisoformat(start_date_time)\n",
    "if time_delta.days > max_days:\n",
    "    end_date_time = str(datetime.fromisoformat(start_date_time) + timedelta(days=max_days))\n",
    "    print(f'end_date_time updated to {end_date_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create a function to download data \n",
    "def download_data_station(station_name, \n",
    "                          client_obj, \n",
    "                          bucket_str, \n",
    "                          prefix_str, \n",
    "                          data_path,\n",
    "                          name_format,\n",
    "                          start_datetime, \n",
    "                          end_datetime):\n",
    "    start_datetime_obj = datetime.fromisoformat(start_datetime) \n",
    "    end_datetime_obj = datetime.fromisoformat(end_datetime)\n",
    "    station_folder = pathlib.Path(data_path).joinpath(station_name)\n",
    "    if not station_folder.exists():\n",
    "        os.mkdir(station_folder)\n",
    "    objects = list(client_obj.list_objects(bucket_str, prefix=prefix_str))\n",
    "    ct = 0\n",
    "    for i, obj in enumerate(objects):\n",
    "        object_name = obj.object_name\n",
    "        path_name = pathlib.Path(object_name).name\n",
    "        if (not path_name.startswith('.')) & path_name.endswith('.nc'):\n",
    "            match = re.findall(r\"_(\\d+)\", path_name)[-1]\n",
    "            file_date = datetime.strptime(match, name_format)\n",
    "            if (file_date >= start_datetime_obj) & (file_date <= end_datetime_obj):\n",
    "                download_path = data_path + '/' + station_name + '/' + pathlib.Path(object_name).name\n",
    "                if os.path.isfile(download_path):\n",
    "                    print('Already downloaded: ' + download_path)\n",
    "                else:\n",
    "                    print('Download ' + str(ct) + ' of ' + str(len(objects)) + ': ' + download_path)\n",
    "                    object_data = client.get_object(bucket, object_name)\n",
    "                    if not os.path.isdir(download_path):\n",
    "                        with open(str(download_path), 'wb') as file_data:\n",
    "                            for data in object_data:\n",
    "                                file_data.write(data)\n",
    "                    file_data.close()\n",
    "            else: \n",
    "                print('Ignored, out of selected period or not a netCDF file ' + path_name)\n",
    "        ct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define file paths -- can be a string glob or list of explicit paths\n",
    "local_path = './../data'\n",
    "sound_paths = local_path + '/' + sound_dataset + '/*.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up the download for NRS11 data \n",
    "client = minio.Minio('storage.googleapis.com')\n",
    "bucket = 'noaa-passive-bioacoustic'\n",
    "prefix = 'soundcoop/%s/' % sound_dataset\n",
    "name_format = '%Y%m%d'\n",
    "download_data_station(sound_dataset, client, bucket, prefix, local_path, name_format=name_format, start_datetime=start_date_time, end_datetime=end_date_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read in and clean up sound data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in data, dropping variables that are sometimes inconsistent across files to \n",
    "# prevent open_mfdataset from complaining\n",
    "sound_ds = xr.open_mfdataset(\n",
    "    sound_paths,\n",
    "    engine='netcdf4'\n",
    ")\n",
    "\n",
    "# Filter data by defined temporal and frequency ranges\n",
    "sound_ds = sound_ds.sel(\n",
    "    time=slice(start_date_time, end_date_time),\n",
    "    frequency=slice(min_frequency, max_frequency)\n",
    ")\n",
    "\n",
    "# Remove data flagged as low quality\n",
    "minimum_quality = 3\n",
    "if hasattr(sound_ds, 'quality_flag'):\n",
    "    sound_ds['psd'] = sound_ds.psd.where(sound_ds.quality_flag <= minimum_quality)\n",
    "\n",
    "sound_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and wrangle environmental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erddap_base_url = 'https://erddap.sensors.ioos.us/erddap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get environmental sensor station lat/lon for use in mapping and querying water temperature climatology data\n",
    "erddap_metadata_url = f'{erddap_base_url}/info/{erddap_dataset}/index.csv'\n",
    "env_metadata_df = pd.read_csv(erddap_metadata_url)\n",
    "\n",
    "env_station_x = env_metadata_df.loc[env_metadata_df['Attribute Name'] == 'geospatial_lon_min']['Value'].item()\n",
    "env_station_y = env_metadata_df.loc[env_metadata_df['Attribute Name'] == 'geospatial_lat_min']['Value'].item()\n",
    "\n",
    "wind_speed_units_row = env_metadata_df[\n",
    "    (env_metadata_df['Row Type'] == 'attribute') & \n",
    "    (env_metadata_df['Attribute Name'] == 'units') & \n",
    "    (env_metadata_df['Variable Name'] == 'wind_speed')\n",
    "]\n",
    "wind_speed_units = wind_speed_units_row.iloc[0]['Value']\n",
    "wind_speed_units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_speed_to_kts_factors = {\n",
    "    \"m.s-1\": 1.94384,\n",
    "    \"mph\": 0.86897423357831,\n",
    "    \"kmh\": 0.53995555554212126825,\n",
    "    \"ft.s-1\": 0.59248243198521155506\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if wind_speed_units in wind_speed_to_kts_factors:\n",
    "    print(\"Success! Units can be converted from\", wind_speed_units,'to','kts')\n",
    "else:\n",
    "    print(\"Error! Wind speed cannot be converted from\", wind_speed_units,'to','kts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab the same time range covered by the sound data\n",
    "time_start = np.datetime_as_string(sound_ds.time.min().to_pandas())\n",
    "time_end = np.datetime_as_string(sound_ds.time.max().to_pandas())\n",
    "\n",
    "wind_var = 'wind_speed'\n",
    "swt_var = 'sea_surface_temperature'\n",
    "wave_var = 'sea_surface_wave_significant_height'\n",
    "anomaly_var = 'swt_anomaly'\n",
    "wind_var_kts = 'wind_speed_kts'\n",
    "\n",
    "erddap_dataset_url = (\n",
    "    f'{erddap_base_url}/tabledap/{erddap_dataset}.csv'\n",
    "    f'?time,{wind_var},{swt_var},{wave_var}&time>={time_start}&time<={time_end}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env_df = pd.read_csv(\n",
    "    erddap_dataset_url,\n",
    "    skiprows=[1]  # The second row (index 1) are the column units, which we don't need\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Format the time field and set it as the index\n",
    "env_df['time'] = pd.to_datetime(env_df['time'])\n",
    "env_df['wind_speed_kts']=env_df['wind_speed'].apply(lambda x : x*wind_speed_to_kts_factors[wind_speed_units])\n",
    "env_df = env_df.set_index('time').sort_index()\n",
    "env_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save CSV of environmental data\n",
    "env_df.to_csv(f'env_df_{erddap_dataset}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map station locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_station_pt = wkt.loads(sound_ds.attrs['geospatial_bounds'])\n",
    "\n",
    "# Some statoins (e.g. PManan) have their WKT coordinates reversed -- should be x, y (long, lat)\n",
    "if sound_station_pt.x > 0:\n",
    "    sound_station_x = sound_station_pt.y\n",
    "    sound_station_y = sound_station_pt.x\n",
    "else:\n",
    "    sound_station_x = sound_station_pt.x\n",
    "    sound_station_y = sound_station_pt.y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(env_station_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_gdf = gpd.GeoDataFrame(\n",
    "    {\n",
    "        'station': [f'{sound_dataset}', f'{erddap_dataset}'],\n",
    "        'geometry': [\n",
    "            geometry.Point(float(sound_station_x), float(sound_station_y)),\n",
    "            geometry.Point(float(env_station_x), float(env_station_y))\n",
    "        ]\n",
    "    },\n",
    "    crs='epsg:4326'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_gdf.hvplot.points(color='station', size=100, geo=True, tiles=True, frame_width=700, frame_height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge sound and environmental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Temporal resolution to which we'll resample the sound and environmental data\n",
    "# in order to merge them and plot them against each other\n",
    "temporal_resolution = 'h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert env_df to an Xarray Dataset so it can be merged with the sound data\n",
    "env_ds = env_df.to_xarray()\n",
    "env_ds['time'] = pd.DatetimeIndex(env_ds['time'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resample sound and environmental data and merge in to a single Xarray Dataset\n",
    "ds = xr.merge([\n",
    "    sound_ds.psd.resample(time=temporal_resolution).median(),\n",
    "    env_ds.resample(time=temporal_resolution).mean()\n",
    "])\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and integrate temperature anomaly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_woa23_temp_at_xy(x, y, month, var='t_mn', depth=0):\n",
    "    \"\"\"\n",
    "    Get 1-degree WOA 2023 temperature values for a given point and month.\n",
    "\n",
    "    Args:\n",
    "        x: A longitude value given in decimal degrees\n",
    "        y: A latitude value given in decimal degrees\n",
    "        month: The month asn integer from which to extract the value\n",
    "        var (optional): The temperature variable to use. Defaults to the statistical mean.\n",
    "        depth (optional): The depth at which to extract the value. Defaults to the surface.\n",
    "    \"\"\"\n",
    "    url = (\n",
    "        'https://www.ncei.noaa.gov/thredds-ocean/dodsC/woa23/DATA/'\n",
    "        f'temperature/netcdf/decav/1.00/woa23_decav_t{month:02}_01.nc'\n",
    "    )\n",
    "    ds = xr.open_dataset(\n",
    "        url,\n",
    "        decode_times=False  # xarray can't handle times defined as \"months since ...\"\n",
    "    )\n",
    "\n",
    "    da = ds.isel(depth=depth)[var]  # Pull out just the variable we're interested in\n",
    "\n",
    "    # Because nearshore locations are often NaN due to the grid's low resolution\n",
    "    # we need to interpolate the NaNs to the nearest non-NaN before extracting our value.\n",
    "    # We use rioxarray to do the interpolations in two dimensions because plain vanilla xarray\n",
    "    # can only interpolate in one dimension.\n",
    "    da = da.rio.write_crs(4326)\n",
    "    da = da.rio.interpolate_na(method='nearest')\n",
    "\n",
    "    # Then we extract the value, also using the nearest neighbor method because the given\n",
    "    # x and y values are unlikely to fall exactly on one of the grid's lat/lon coordinate pairs\n",
    "    val = da.sel(lon=x, lat=y, method='nearest').item()\n",
    "\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the location of our selected ERDDAP dataset\n",
    "# Override here if needed\n",
    "x = env_station_x\n",
    "y = env_station_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\n",
    "    'https://www.ncei.noaa.gov/thredds-ocean/dodsC/woa23/DATA/'\n",
    "    f'temperature/netcdf/decav/1.00/woa23_decav_t07_01.nc'\n",
    ")\n",
    "da = xr.open_dataset(\n",
    "    url,\n",
    "    decode_times=False  # xarray can't handle times defined as \"months since ...\"\n",
    ").isel(depth=0)['t_mn']  # Pull out just the variable we're interested in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Because nearshore locations are often NaN due to the grid's low resolution\n",
    "# we need to interpolate the NaNs to the nearest non-NaN before extracting our value.\n",
    "# We use rioxarray to do the interpolations in two dimensions because plain vanilla xarray\n",
    "# can only interpolate in one dimension.\n",
    "da = da.rio.write_crs(4326)\n",
    "da = da.rio.interpolate_na(method='nearest')\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we extract the value, also using the nearest neighbor method because the given\n",
    "# x and y values are unlikely to fall exactly on one of the grid's lat/lon coordinate pairs\n",
    "val = da.sel(lon=x, lat=y, method='nearest').item()\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assemble a mapping between months and WOA 2023 temperature values\n",
    "months = list(range(1, 13))\n",
    "temps = [get_woa23_temp_at_xy(x, y, m) for m in months]\n",
    "clim_dict = {m: t for m, t in zip(months, temps)}\n",
    "clim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the sea water temperature anomaly by subtracting the monthly WOA 2023 temperature value\n",
    "# from each measured sea water temperature value and store it as a new variable\n",
    "ds[anomaly_var] = ds[swt_var] - [clim_dict[m] for m in ds.time.dt.month.values]\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save NetCDF of merged data\n",
    "ds.to_netcdf(f'merged_data_{sound_dataset}_{erddap_dataset}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save CSV of merged data\n",
    "ds.to_dataframe().to_csv(f'merged_data_{sound_dataset}_{erddap_dataset}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot resampled raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot resampled sound data\n",
    "ds.psd.plot(x='time', yscale='log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot resampled wind data\n",
    "ds[wind_var_kts].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot resampled wave data\n",
    "ds[wave_var].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot resampled water temperature data\n",
    "ds[swt_var].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot water temperature anomaly data\n",
    "ds[anomaly_var].plot(linestyle='')\n",
    "plt.fill_between(ds.time, ds[anomaly_var], 0, where=(ds[anomaly_var] < 0), facecolor='blue', alpha=0.5)\n",
    "plt.fill_between(ds.time, 0, ds[anomaly_var], where=(ds[anomaly_var] >= 0), facecolor='red', alpha=0.5)\n",
    "plt.axhline(0, color='k', linestyle='--', linewidth=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot power spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_power_spec(\n",
    "    ds, \n",
    "    conditions=None,\n",
    "    title=None,\n",
    "    xlabel='Frequency (hz)', \n",
    "    ylabel='Sound pressure level (db)', # use netcdf attribute\n",
    "    envelope=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Produces power spec plot given zero or more conditions and labels\n",
    "\n",
    "    Args:\n",
    "        ds: An Xarray Dataset consisting of both sound and environmental variables.\n",
    "        conditions (optional): A single tuple or list of tuples, where each tuple is \n",
    "            a condition-label pair, the condition representing a conditional statement to\n",
    "            be passed to ds.where() and each label representing that condition's legend label.\n",
    "        title (optional): The plot title.\n",
    "        xlabel (optional): The X-axis label.\n",
    "        ylabel (optional): The Y-axis label.\n",
    "        envelope (optional): Whether or not to plot the 10th to 90th quantile envelope\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # If no conditions were specified, just plot everything\n",
    "    if conditions is None:\n",
    "        ds.psd.median(dim='time').plot(x='frequency', xscale='log', ax=ax)\n",
    "\n",
    "        # Add 10th to 90th quantile envelope\n",
    "        if envelope:\n",
    "            plt.fill_between(\n",
    "                ds.frequency,\n",
    "                ds.psd.chunk(dict(time=-1)).quantile(0.9, dim='time'),\n",
    "                ds.psd.chunk(dict(time=-1)).quantile(0.1, dim='time'),\n",
    "                alpha=0.25\n",
    "            )\n",
    "\n",
    "    else:\n",
    "\n",
    "        # If conditions is a tuple (i.e. a single condition), wrap it in a list so it's iterable\n",
    "        if isinstance(conditions, tuple):\n",
    "            conditions = [conditions]\n",
    "\n",
    "        # Plot each condition in turn\n",
    "        for c, l in conditions:\n",
    "\n",
    "            da = ds.where(c, drop=True).psd\n",
    "\n",
    "            # Only plot if result of where operation has data\n",
    "            if len(da) > 0:\n",
    "                da.median(dim='time').plot(x='frequency', xscale='log', ax=ax, label=l)\n",
    "\n",
    "                # Add 10th to 90th quantile envelope\n",
    "                if envelope:\n",
    "                    plt.fill_between(\n",
    "                        da.frequency,\n",
    "                        da.chunk(dict(time=-1)).quantile(0.9, dim='time'),\n",
    "                        da.chunk(dict(time=-1)).quantile(0.1, dim='time'),\n",
    "                        alpha=0.25\n",
    "                    )\n",
    "\n",
    "        ax.legend()\n",
    "    \n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot everything\n",
    "plot_power_spec(ds, title='Power spec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot wind speed intervals\n",
    "plot_power_spec(\n",
    "    ds,\n",
    "    conditions=[\n",
    "        (ds[wind_var_kts] <= 10, '< 10 kts'),\n",
    "        ((ds[wind_var_kts] > 10) & (ds[wind_var] <= 20), '> 10 kts, < 20 kts'),\n",
    "        (ds[wind_var_kts] > 20, '> 20 kts')\n",
    "    ],\n",
    "    title='Power spec by wind speed intervals'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot waves height intervals\n",
    "plot_power_spec(\n",
    "    ds,\n",
    "    conditions=[\n",
    "        (ds[wave_var] <= 1, '< 1 m'),\n",
    "        ((ds[wave_var] > 1) & (ds[wave_var] <= 3), '> 1 m, < 3 m'),\n",
    "        (ds[wave_var] > 3, '> 3 m')\n",
    "    ],\n",
    "    title='Power spec by wave height intervals'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot temperature anomaly intervals\n",
    "plot_power_spec(\n",
    "    ds,\n",
    "    conditions=[\n",
    "        (ds[anomaly_var] < -2, '< -2 °C'),\n",
    "        ((ds[anomaly_var] < -.5) & (ds[anomaly_var] >= -2), '> -2 °C < -0.5 °C'),\n",
    "        ((ds[anomaly_var] < .5) & (ds[anomaly_var] >= -.5), '> -0.5 °C < 0.5 °C'),\n",
    "        ((ds[anomaly_var] >= .5) & (ds[anomaly_var] <= 2), '> 0.5 °C < 2 °C'),\n",
    "        (ds[anomaly_var] > 2, '> 2 °C')\n",
    "    ],\n",
    "\n",
    "    title='Power spec by temperature anomaly intervals'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
